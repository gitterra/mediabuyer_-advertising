# -*- coding: utf-8 -*-
"""Медиатека классификация v3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kr68zWdXaoPfW77qb-HjSNinb9HDvXIO

# ИНФО

Модель классификации

Доработки:


1.   На остове колонки spotDay добавлены колонки spotMonth (месяц), weedDay (день недели), weekEnd(рабочий/выходной)
2.   Все пустые поля заполены '-'
3.   На остове квантилей по колонкам с показателяти звонков ограничен диапазон значений по верхней границе в районе 97%. Т.е. оставшимся 3% присвоены максимальные выбранные значения для этих данных. Максимальные значения задаются в словаре columnsY_maxval. 
4.   Добавлена колонка genre_class на основе классификации Антона колонки genre.
5.   Добавлен выбор диапазонов классов звонков для каждого предсказываемого значения отдельно. Значения задаются в словаре rangeCalls. Например для значения 10 - ширина класса будет в 10 звонков (0-10, 10-20, 20-30 ... )
6.   Для каждого предсказанного значения рассчитывается MAE. За значение предсказанного класса берется среднее значение диапазона класса. Например класс '10-20' имеет среднее значение 15. Допустим правильное значение 12, то абсолютная ошибка будет 15-12=3.
7.   Добавлен словарь dataX_for_site_dict для отображения полей и их значений на сайте для ввода входных значений для единичного предсказания.

# Корневой каталог
"""

path_main = '/content/drive/MyDrive/КУРСЫ/УИИ/СТАЖИРОВКА 202209/НС/v3/'

"""# Импорт Библиотек"""

import numpy as np #Библиотека работы с массивами
import pandas as pd # Библиотека для работы с базами

from tensorflow.keras.models import Sequential, Model, load_model # 
from tensorflow.keras.layers import concatenate, Input, Dense, Dropout, BatchNormalization, Flatten #
from tensorflow.keras import utils #Используем для to_categoricall
from tensorflow.keras.optimizers import Adam,Adadelta,SGD,Adagrad,RMSprop #
from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence #
from tensorflow.keras.preprocessing.sequence import pad_sequences #
from tensorflow.keras.callbacks import LambdaCallback # подключаем колбэки

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split # Для разбивки на выборки
import joblib # для сохранения MinMaxScaler

import matplotlib.pyplot as plt #

import pickle # для записи словаря в файл в формате JSON

"""# Функции

## Сохранить|загрузить данные в файл
"""

def save_data(path, data):
  """
  Сохраняет словарь в файл
  pathe - путь к файлу
  data - сохраняемые данные (словарь, список и т.д.)

  Описание https://pythonworld.ru/moduli/modul-pickle.html
  """

  with open(path, 'wb') as f:
    pickle.dump(data, f)

  
def load_data(path):
  """
  Загружает словарь из файла
  path - путь к файлу

  Возвращает:
  data - загруженные данные (словарь, список и т.д.)

  Описание https://pythonworld.ru/moduli/modul-pickle.html
  """

  with open(path, 'rb') as f:
    return pickle.load(f)

"""## Сохранить|загрузить словарь"""

def save_dict(path, data_dict):
  """
  Сохраняет словарь в файл
  path - путь к файлу
  data_dict - словарь
  """

  save_data(path, data_dict)

  
def load_dict(path):
  """
  Загружает словарь из файла
  path - путь к файлу

  Возвращает:
  data_dict - словарь
  """

  data_dict = load_data(path)

  return data_dict

"""## Сохранить|загрузить маску"""

def save_masks(path, mask_train, mask_test):
  """
  Сохраняет словарь в файл
  path - путь к файлу
  mask_train - маска тренировочная
  mask_test - маска проверочная
  """
  mask = {'mask_train' : mask_train,
          'mask_test' : mask_test}

  save_data(path, mask)

  
def load_masks(path):
  """
  Загружает словарь из файла
  path - путь к файлу

  Возвращает:
  mask_train - маска тренировочная
  mask_test - маска проверочная
  """

  mask = load_data(path)

  return mask['mask_train'], mask['mask_test']

"""# Подготовка БД"""

from google.colab import drive
drive.mount('/content/drive')

"""##Загружаем базу и смотрим содержание"""

df_db = pd.read_csv(path_main + 'db_csv.csv', sep=',')
df_db.head(5)

"""##Оставляем только нужное из базы"""

# Имена колонок с входными данными
#columnsX = ['advertiser', 'product', 'TVChannel', 'spread', 'spotLine', 'spotDay', 'spotDuration']
columnsX = ['advertiser', 'product', 'TVChannel', 'spread', 'genre', 'spotLine', 'spotDay', 'spotDuration']
# Имена колонок с выходными данными
columnsY = ['AllCalls', 'calls(0)', 'calls(-2)', 'calls(-4)', 'calls(-7)']

columns = columnsX + columnsY
df_data = pd.DataFrame(data=df_db[columns], index=None, columns=columns, dtype=None)
df_data['spotDay'] = pd.to_datetime(df_data['spotDay'], errors='coerce') # задаём тип столбцу spotDay

# колонку spotDuration переводим в тип object
df_data['spotDuration'] = df_data['spotDuration'].astype(str)

# Перевод spotLine в формат 00:00:00, чтобы удобно было сортировать
df_data['spotLine'] = pd.to_datetime(df_data['spotLine']) # задаём тип столбцу spotLine
df_data['spotLine'] = df_data['spotLine'].dt.strftime('%H:%M:%S')
print(df_data.dtypes)
df_data

"""## Подчищаем базу от NaN"""

# все пустые (не заполненные) ячейки в колонках типа object меняем на '-'
df_data.fillna(
    value = {'advertiser': '-',
             'product': '-',
             'TVChannel': '-',
             'spread': '-',
             'genre': '-',
             'spotLine': '-',
             'spotDuration': '-'}, 
    inplace=True)

# Проверяем на пустые значения
df_data.isna().sum()

"""## Расширяем базу"""

# Словарь типов тв-программ
genre_map = { 0 : '-',
              1 : 'Кино, сериалы и анимация',
              2 : 'Люди и общество (шоу)',
              3 : 'Документальная программа, сериал',
              4 : 'Новости и политика',
              5 : 'Развлечения',
              6 : 'Игры',
              7 : 'Образование, познавательная программа',
              8 : 'Музыка',
              9 : 'Для всей семьи',     
              10 : 'Кулинария',
              11 : 'Прочее'}

# Словарь соответствий тв-программ типам
genre_mapping = {'-': 0,
              'Документальная программа': 3,
              'Познавательная программа': 7,
              'Анимация': 1,
              'Социально-политическая программа': 4,
              'Новости': 4,
              'Развлекательная программа': 5,
              'Кинофильм': 1,
              'Телесериал': 1,
              'Детская программа': 9,
              'Музыкальная программа': 8,
              'Прочее': 11,
              'Сериал (Сериал "Морские дьяволы. Смерч - 2.")': 1,
              'ЗА ГРАНЬЮ': 2, 
              'Место встречи': 4,
              'Сериал (Сериал "Морские дьяволы. Смерч-3")': 1,
              'Ток-шоу «ДНК»': 2,
              'Сериал (Сериал "МОРСКИЕ ДЬЯВОЛЫ. РУБЕЖИ РОДИНЫ")': 1,
              'ОТРИЦАТЕЛИ БОЛЕЗНЕЙ (Научное расследование Сергея Малоземова)': 2,
              'Сериал (Сериал "Морские дьяволы. Смерч")': 1,
              'Новые русские сенсации': 4,
              'Следствие вели...': 3,
              'Обзор. Чрезвычайное происшествие': 4,
              'Сериал (Сериал "Морские дьяволы. Смерч. Судьбы.")': 1,
              'Сегодня/Сегодня в Москве': 4,
              'Сериал (Сериал "Морские дьяволы. Смерч. Судьбы-2")': 1,
              'Сериал (Сериал "АЛЕКС ЛЮТЫЙ. ДЕЛО ШУЛЬЦА")': 1,
              'Сериал (Сериал "Береговая охрана 2")': 1,
              'Сериал (Сериал "Морские дьяволы 3")': 1,
              'Сериал (Сериал "Морские дьяволы 4")': 1,
              'Док. сериал (Д/ф "Знаки судьбы")': 1,
              'Док. сериал (Д/ф "Гадалка")': 1,
              'Док. сериал (Д/ф "СЛЕПАЯ")': 1,
              'Мистические истории': 1,
              'Док. сериал (Д/ф "Уиджи")': 1,
              'Вернувшиеся': 1,
              'Док. сериал (Д/ф "Врачи")': 1,
              'НОВЫЙ ДЕНЬ': 1,
              'Р/б после мультфильмов до M/ф "Возвращение Домовенка"': 9,
              'Своя игра': 5,
              'Сериал (Сериал "Пять минут тишины. Возвращение")': 1,
              'Сериал (Сериал "Морские дьяволы. Судьбы - 2")': 1,
              'Сериал (Сериал "Ментовские войны - 7")': 1,
              'ЖДИ МЕНЯ': 2,
              'Сериал (Сериал "ПЕРВЫЙ ОТДЕЛ")': 1,
              'Шоу «Маска»': 8,
              'Ты не поверишь!': 2,
              'Сериал (Сериал "ПЕРВЫЙ ОТДЕЛ-2")': 1,
              'Документальный фильм (Д/ф "МОИ УНИВЕРСИТЕТЫ. БУДУЩЕЕ ЗА НАСТОЯЩИМ")': 7,
              'Лотерея "У НАС ВЫИГРЫВАЮТ!"': 6,
              'Сериал (Сериал "ПОРТ")': 1,
              'Страна талантов': 2,
              'Сериал (Сериал "Морские дьяволы. Особое задание")': 1,
              'Сериал (Сериал "АНОНИМНЫЙ ДЕТЕКТИВ")': 1,
              'По следу монстра': 1,
              'Сериал (Сериал "Красная зона")': 1,
              'Сериал (Сериал "Шеф 2")': 1,
              'Сериал (Сериал "Морские дьяволы 5")': 1,
              'Сериал (Сериал "Шеф. Новая жизнь")': 1,
              'Сериал (Сериал "Морские дьяволы. Северные рубежи")': 1,
              'Документальный фильм (Д/ф "Анна")': 1,
              'Секрет на миллион': 2,
              'Сериал (Сериал "Балабол-4")': 1,
              'Сериал (Сериал "По ту сторону смерти")': 1,
              'Сериал (Сериал "Сверхъестественное")': 1,
              'Худ. фильм (Х/ф "Хоббит: Пустошь Смауга")': 1,
              'Сериал (Сериал "Ментовские войны - 10")': 1,
              'Сериал (Сериал "Ментовские войны - 11")': 1,
              'Сегодня (вых)': 4,
              'ШОУМАСКГООН': 2,
              'Документальный фильм (Д/ф "ЧЕРНОМОРСКИЙ ЦУГЦВАНГ. ГИБЕЛЬ ТЕПЛОХОДА «АРМЕНИЯ")': 3,
              'Сериал (Сериал "МОРСКИЕ ДЬЯВОЛЫ. ДАЛЬНИЕ РУБЕЖИ")': 1,
              'Док. сериал (Д/ф "Старец")': 1,
              'Добрый день с Валерией': 2,
              'Р/б после мультфильмов до M/ф "В тридесятом веке"': 9,
              'Худ.фильм (Х/ф "Хоббит: Нежданное путешествие")': 1,
              'Худ.фильм (Х/ф "Хоббит: Пустошь Смауга")': 1,
              'Худ. фильм (Х/ф "Хоббит. Битва пяти воинств")': 1,
              'Худ.фильм (Х/ф "Последний легион")': 1,
              'Худ.фильм (Х/ф "Белоснежка: месть гномов")': 1,
              'Худ. фильм (Х/ф "Царство небесное")': 1,
              'Р/б после мультфильмов до M/ф "Влюбчивая ворона"': 9,
              'Звёзды сошлись': 2,
              'Готовим с Алексеем Зиминым': 10,
              'Сериал (Сериал "Невский. Проверка на прочность")': 1,
              'Сериал (Сериал "Проверка на прочность")': 1,
              'Сериал (Сериал "Невский. Чужой среди чужих")': 1,
              'Сериал (Сериал "ГОРЯЧАЯ ТОЧКА-2")': 1,
              'НОВОГОДНЯЯ МАСКА 2022': 2,
              'Сериал (Сериал "Невский")': 1,
              'ЧП.Расследование': 4,
              'Художественный фильм (Х/ф "Чёрный пёс")': 1,
              'Художественный фильм (Х/ф "БАТАЛЬОН")': 1,
              'Сегодня': 4,
              'Сериал (Сериал "Чингачгук")': 1,
              'ОСНОВАНО НА РЕАЛЬНЫХ СОБЫТИЯХ': 4,
              'Сериал (Сериал "Дельфин")': 1,
              'НЕВЕДОМЫЕ ЧУДОВИЩА НА ЗЕМЛЕ (Научное расследование Сергея Малоземова)': 2,
              'Сериал (Сериал "ПОЛИЦЕЙСКОЕ БРАТСТВО")': 1,
              'Сериал (Сериал "ПРАКТИКАНТ 2")': 1,
              'Худ. фильм (Х/ф "Заложница 3")': 1,
              'Худ. фильм (Х/ф "ШУТКИ В СТОРОНУ-2. МИССИЯ В МАЙАМИ")': 1,
              'Художественный фильм (Х/ф "Отставник. Один за всех")': 1,
              'Художественный фильм (Х/ф "Отставник. Спасти врага")': 1,
              'Художественный фильм (Х/ф "ДИНА И ДОБЕРМАН")': 1,
              'Пресс-конференция по итогам встречи министров иностранных дел РФ и Украины': 4,
              '"ТАЙНЫЕ РЕЦЕПТЫ НЕОФИЦИАЛЬНОЙ МЕДИЦИНЫ". Научное расследование Сергея Малозёмова': 2,
              'ТЫ СУПЕР! 60+': 2,
              'Сериал (Сериал "Вспышка")': 1,
              'Сериал (Сериал "Заповедный спецназ")': 1,
              '«ЧТО МОГУТ ЭКСТРАСЕНСЫ?». НАУЧНОЕ РАССЛЕДОВАНИЕ СЕРГЕЯ МАЛОЗЁМОВА': 2}

# Словарь с данными для преобразования колонок
genres_dict = {'genre_map' : genre_map,
               'genre_mapping' : genre_mapping}

# Сохраняем полученный словарь в файл dict_genres.pkl
save_dict(path_main + 'dicts_class/dict_genres.pkl', genres_dict)

def expand_data(df_data):
    """
    Расширяем входные данные
    Добавляем колонки: spotMonth, weekDay, weekEnd, 
    genre_class (на остове словарей genre_map и genre_mapping)
    :return: Расширенный датафрейм
    """

    # Получаем значения месяцев 1-12
    df_data['spotMonth'] = df_data['spotDay'].dt.month
    # Получаем значения дней недели 0-6
    df_data['weekDay'] = df_data['spotDay'].dt.weekday

    # Получаем значения рабочий/выходной 0
    arr = []
    for day in df_data['spotDay'].dt.weekday:
      if day > 4:
        arr += [1]  # рабочий - 1
      elif np.isnan(day):
        arr += [None]  # дата не определена - NaN
      else: 
        arr += [0]  # выходной - 0
    df_data['weekEnd'] = arr

    # Добавляем колонку genre_class
    arr = []
    for genre in df_data['genre']:
      genre_map = genres_dict['genre_map']
      genre_mapping = genres_dict['genre_mapping'] 
      arr += [genre_map[genre_mapping[genre]]]
    df_data.loc[:,'genre_class'] = arr

    return df_data

df_data = expand_data(df_data)

# Имена колонок с расширенными входными данными
columnsX_plus = columnsX + ['spotMonth', 'weekDay', 'weekEnd']

print(df_data.dtypes)
df_data

"""## Анализирум выходные данные

### Квантили
"""

# Распределение значений в колонке
df_data.quantile([0.8, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 0.995])

"""### Гистограмма"""

# Задаем пространство для подграфиков
f, axes = plt.subplots(5, 1, figsize=(25,15))

# Гистограмма распределения значений в массиве
for i, col_name in enumerate(columnsY):
  color = 'g' 
  if (i == 0): color = 'tab:orange'
  axes[i].hist(df_data[col_name].values, bins=100, color=color) # параметр bins отвечает за количество подгрупп, в которые объединяются данные 
  axes[i].set_ylabel(col_name)

plt.show()

"""### Выбор максимальных значений

Т.к. большая часть выходных значений в БД ближе к нулю, то выберем максимально допустимые значения для колонок 

columnsY = ['AllCalls', 'calls(0)', 'calls(-2)', 'calls(-4)', 'calls(-7)']
"""

# Выберем максимальные значения для выходных данных
columnsY_maxval = {'AllCalls': 200, 
                    'calls(0)': 100, 
                    'calls(-2)': 30, 
                    'calls(-4)': 40, 
                    'calls(-7)': 20}

"""### Выбор диапазонов классов для кол-ва звонков

"""

# Выберем диапазоны классов для кол-ва звонков
rangeCalls = {'AllCalls': 15, 
              'calls(0)': 8, 
              'calls(-2)': 3, 
              'calls(-4)': 4, 
              'calls(-7)': 2}

"""## Обрезаем выходные значения

Обрежем значения в колонках

columnsY = ['AllCalls', 'calls(0)', 'calls(-2)', 'calls(-4)', 'calls(-7)']

которые выше значений в указанных в словаре columnsY_maxval для колонок.


"""

def set_max_dataY(df_data, columnsY, columnsY_maxval):
  """
  Обрезаем масимальные значения выходных данных в колонках columnsY у df_data
  по значениям в columnsY_maxval
  """
  
  # Цикл по выходным колонкам
  for col_name in columnsY:
    df_col = df_data[col_name].copy()                                           # Копируем колонку
    max_val = columnsY_maxval[col_name]                                         # Определяем максимальное значение
    mask = df_col[:] > max_val                                                  # Находим строки, где значения > заданных в columnsY_maxval
    df_col.loc[mask] = max_val                                                  # Присваиваем максимальные значения из columnsY_maxval
    df_data.loc[:, col_name] = df_col                                           # Сохраняем значения в датафрейме


# Обрезаем выходные значения
set_max_dataY(df_data, columnsY, columnsY_maxval)

# Проверяем результат
df_data.describe()

"""## Классифицируем выходные данные

"""

def set_class_dataY(df_data, columnsY_maxval, rangeCalls):
  """
    Добавляет колонку с названиями классов по кол-ву звонков и формируем словарь
    со средними значениями классов (для расчёта MAE)
    |---------------------------|
    | AllCalls | AllCalls_class |
    |   139    |     130-140    |
    |    47    |      40-50     |
    |---------------------------|
  """
  df = df_data.copy()
  class_mean_dict = {}                                                          # Словарь для средних значений классов

  # Цикл по выходным колонка со звонками
  for col in columnsY:
    maxval = columnsY_maxval[col]                                               # максимальное значение выходных данных для текущей колонки
    delta = rangeCalls[col]                                                     # ширина диапазона для одного класса
    # print()
    # print(col)
    cls = col+'_class'                                                          # имя колонки с классами
    df[cls] = ''                                                                # создаём пустую колонку с классами
    # Цикл по диапазонам в пределах от 0 до maxval
    for min in range(0, maxval, delta):                                         # min минимальное значение диапазона >=
      max = min + delta                                                         # max максимальное значение диапазона < (кроме последнего)
      final = False                                                             # final - флаг 'последний диапазон'
      if max >= maxval:                                                         # Проверка на выход диапазона за максимальное значение
        max = maxval                                                            # Ограничиваем последний диапазон максимальным значением
        final = True                                                            # Выставляем флаг 'последний диапазон'
      class_name = str(min) + '-' + str(max)                                    # Формируем название диапазона
      # print(class_name + ' ', end='')

      if final:                                                                 # Если диапазон последний
        mask = (df[col] >= min) & (df[col] <= max)                              # Маска значений, которые входят в диапазон, включая максимальное значение
      else:
        mask = (df[col] >= min) & (df[col] < max)                               # Маска значений, которые входят в диапазон, НЕ включая максимальное значение
      
      df.loc[mask, cls] = class_name                                            # Заполняем колонку с названием класса

      class_mean_dict[class_name] = (max + min) / 2.0                           # Заполняем словарь со средними значениями классов

  return df, class_mean_dict

df_data, class_mean_dict = set_class_dataY(df_data, columnsY_maxval, rangeCalls)

# Сохраняем полученный словарь со средними значениями классов в файл class_mean.pkl
save_dict(path_main + 'dicts_class/class_mean.pkl', class_mean_dict)

df_data

class_mean_dict

"""## Парсим базу в OHE

### dataX_OHE, dataX_dict
"""

def words_to_OHE(df_col):
  '''
    Входной массив преобразуется в OHE
    Размер OHE определяется автоматически

    df_col = ['-', 'РД1', 'РД2', 'РД1', 'РД3', 'РД3', 'РД4', 'РД4']
    words_dict = {'-': 0, 'РД1': 1, 'РД2': 2, 'РД3': 3, 'РД4': 4}
    words_OHE =   array([[0., 0., 0., 0.],    '-' - отбрасывается при приведении к OHE
                         [1., 0., 0., 0.],
                         [0., 1., 0., 0.],
                         [1., 0., 0., 0.],
                         [0., 0., 1., 0.],
                         [0., 0., 1., 0.],
                         [0., 0., 0., 1.],
                         [0., 0., 0., 1.]], dtype=float32)
  
    Все строковые значения, которые не указаны в таблице, значаться как '-'
  '''

  # Удаляем '-' из массива уникальных значений
  unique = df_col.unique()
  if '-' in unique:
    unique = list(unique)
    unique.remove('-')
    unique = np.array(unique)

  # Получаем словарь с уникальными значениями
  words_dict = {j: i+1 for i, j in enumerate(unique)}
  # Принудительно назначаем {'-': 0}
  words_dict['-'] = 0

  # Получаем OHE, где перый элемент отвечает за '-'
  words_OHE = np.array(utils.to_categorical([words_dict[i] for i in df_col.values], num_classes=len(words_dict)))

  # Удаляем первый элемент из OHE. Тогда везде, где встречается '-' будет OHE с нулями [0, 0 ... 0, 0]
  words_OHE = words_OHE[:, 1:]

  #print(words_dict)
  #print(words_OHE)

  return words_OHE, words_dict


def getDataX(df_data):
  '''
    Подготовка датасета по входным параметрам
  '''
  dataX_dict = {}
  advertiser_OHE, dataX_dict['advertiser_dict'] = words_to_OHE(df_data.advertiser)
  product_OHE, dataX_dict['product_dict'] = words_to_OHE(df_data['product'])
  TVChannel_OHE, dataX_dict['TVChannel_dict'] = words_to_OHE(df_data.TVChannel)
  spread_OHE, dataX_dict['spread_dict'] = words_to_OHE(df_data.spread)
  _, dataX_dict['genre_dict'] = words_to_OHE(df_data.genre)
  genre_class_OHE, dataX_dict['genre_class_dict'] = words_to_OHE(df_data.genre_class)
  spotLine_OHE, dataX_dict['spotLine_dict'] = words_to_OHE(df_data.spotLine)
  spotDuration_OHE, dataX_dict['spotDuration_dict'] = words_to_OHE(df_data.spotDuration)

  # все пустые (не заполненные) ячейки в колонке spotMonth меняем на 13
  df_data.fillna(
      value = {'spotMonth': 13}, 
      inplace=True)
  spotMonth_OHE = utils.to_categorical(df_data['spotMonth'].values - 1, num_classes=13)
  # Удаляем последний элемент из OHE. Тогда везде, где встречается 'NaN' будет OHE с нулями [0, 0 ... 0, 0]
  spotMonth_OHE = spotMonth_OHE[:, :-1]

  # все пустые (не заполненные) ячейки в колонке weekDay меняем на 7
  df_data.fillna(
      value = {'weekDay': 7}, 
      inplace=True)
  weekDay_OHE = utils.to_categorical(df_data['weekDay'].values, num_classes=8)
  # Удаляем последний элемент из OHE. Тогда везде, где встречается 'NaN' будет OHE с нулями [0, 0 ... 0, 0]
  weekDay_OHE = weekDay_OHE[:, :-1]

  # все пустые (не заполненные) ячейки в колонке weekEnd меняем на 2
  df_data.fillna(
      value = {'weekEnd': 2}, 
      inplace=True)
  weekEnd_OHE = utils.to_categorical(df_data['weekEnd'].values, num_classes=3)
  weekEnd_OHE = weekEnd_OHE[:, :-1]

  # Объединяем все OHE в один вектор
  dataX_OHE = np.hstack([advertiser_OHE, product_OHE, TVChannel_OHE, spread_OHE, genre_class_OHE, spotLine_OHE, spotDuration_OHE, spotMonth_OHE, weekDay_OHE, weekEnd_OHE])

  print('dataX_OHE:')
  print(dataX_OHE)
  for x in dataX_dict:
    print(x + ': ', end='')
    print(dataX_dict[x])

  return dataX_OHE, dataX_dict

# Получаем dataX в OHE
dataX_OHE, dataX_dict = getDataX(df_data)

# Сохраняем полученный словарь в файл dictX.pkl
save_dict(path_main + 'dicts_class/dictX.pkl', dataX_dict)

"""### dataY_OHE_dict, dataY_dict"""

def words_Y_to_OHE(df_col):
  '''
    Входной массив преобразуется в OHE
    Размер OHE определяется автоматически

    df_col = ['0-10', '10-20', '20-30', '10-20', '30-40', '0-10', '20-30']
    words_dict = {'0-10': 0, '10-20': 1, '20-30': 2, '30-40': 3}
    words_OHE =   array([[1., 0., 0., 0.],
                         [0., 1., 0., 0.],
                         [0., 0., 1., 0.],
                         [0., 1., 0., 0.],
                         [0., 0., 0., 1.],
                         [1., 0., 0., 0.],
                         [0., 0., 1., 0.]], dtype=float32)
  '''

  # Удаляем '-' из массива уникальных значений
  unique = df_col.unique()

  # Получаем словарь с уникальными значениями
  words_dict = {j: i for i, j in enumerate(unique)}

  # Получаем OHE
  words_OHE = np.array(utils.to_categorical([words_dict[i] for i in df_col.values], num_classes=len(words_dict)))

  return words_OHE, words_dict


def getDataY(df_data):
  '''
    Подготовка выходных данных датасета
  '''
  dataY_OHE_dict, dataY_dict = {}, {}

  dataY_OHE_dict['AllCalls'], dataY_dict['AllCalls_class_dict'] = words_Y_to_OHE(df_data['AllCalls_class'])
  dataY_OHE_dict['calls(0)'], dataY_dict['calls(0)_class_dict'] = words_Y_to_OHE(df_data['calls(0)_class'])
  dataY_OHE_dict['calls(-2)'], dataY_dict['calls(-2)_class_dict'] = words_Y_to_OHE(df_data['calls(-2)_class'])
  dataY_OHE_dict['calls(-4)'], dataY_dict['calls(-4)_class_dict'] = words_Y_to_OHE(df_data['calls(-4)_class'])
  dataY_OHE_dict['calls(-7)'], dataY_dict['calls(-7)_class_dict'] = words_Y_to_OHE(df_data['calls(-7)_class'])

  return dataY_OHE_dict, dataY_dict

# Получаем dataY в OHE
dataY_OHE_dict, dataY_dict = getDataY(df_data)

# Сохраняем полученный словарь в файл dictY.pkl
save_dict(path_main + 'dicts_class/dictY.pkl', dataY_dict)

# Проверяем
number_rows = 777 
print('В датафрейме: ', df_data.loc[number_rows, 'AllCalls_class'])
print('Словарь: ', dataY_dict['AllCalls_class_dict'])
print('Индекс в OHE', np.argmax(dataY_OHE_dict['AllCalls'][number_rows]))
print('В OHE: ', dataY_OHE_dict['AllCalls'][number_rows])

"""### dataX_for_site_dict"""

"""
  Формируем данные в виде списка для заполнения входных полей на сайте
  [{'name': 'TVChannel':         - название поля
    'type': 'string',            - тип поля (object - string, datetime64 - date, int64 - number)
    'num_classes': 10,           - кол-во классов (длина словаря values)
    'values': {'-': 0,           - словарь со значениями полей и номером класса для OHE
              'ГНЦ': 1,
              'НЦЗ': 2}}, ...]
"""
dataX_for_site = []
for name in columnsX:
  field = {'name': name}                    # название поля

  type_field = '-'
  values = {}
  if df_data[name].dtype == 'O':
    type_field = 'string'
    values = dataX_dict[name + '_dict']
  elif df_data[name].dtype == 'int64':
    type_field = 'number'
  elif df_data[name].dtype == '<M8[ns]':
    type_field = 'date'
  field['type'] = type_field                # тип поля (object - string, datetime64 - date, int64 - number)

  num_classes = len(values)                 

  field['num_classes'] = num_classes        # кол-во классов (длина словаря values)

  values = dict(sorted(values.items()))     # сортировка
  field['values'] = values                  # словарь со значениями полей и номером класса для OHE

  dataX_for_site += [field]                 # добавляем в список

# Сохраняем полученный словарь в файл dataX_for_site.pkl
save_dict(path_main + 'dicts_class/dataX_for_site.pkl', dataX_for_site)

# пример
dataX_for_site[5:8]

"""## Обучающая и тестовая выборки"""

print('Размерность входных данных: ' + str(dataX_OHE.shape))
for name_col in dataY_OHE_dict:
  print('Размерность выходных данных ' + name_col +': ' + str(dataY_OHE_dict[name_col].shape))

# Пример входных и выходных данных
number_rows = 555
print(dataX_OHE[number_rows])
print(dataY_OHE_dict['AllCalls'][number_rows])

"""### Маска train и test"""

# Делим датасет на обучающую и проверочную выборки
# Длина датасета
len_db = len(dataX_OHE)                                                         
print('Длина датасета: ', len_db)

# Маски для тренировочной и проверочной выборок
mask_train, mask_test = train_test_split(np.arange(len_db), test_size = 0.1)

print('Длина тренировочной выборки: ', len(mask_train))
print('Длина проверочной выборки: ', len(mask_test))

# Сохраняем полученные маски в файл masks.pkl
save_masks(path_main + 'masks_class/masks.pkl', mask_train, mask_test)

# Загружаем маски из файла masks.pkl
mask_train, mask_test = load_masks(path_main + 'masks_class/masks.pkl')

"""### x_train, x_test, y_train, y_test"""

def get_train_test_split(dataX, dataY, mask_train, mask_test, columnsY):
  '''
    Делит датасет на обучающую и проверочную выборки так,
    чтобы для всех выходных данных в dataY значения были из одной строки
  '''
  y_train, y_test = {}, {}

  # Разбиваем на тренировочную и проверочную для dataX
  x_train = dataX[mask_train]
  x_test = dataX[mask_test]

  # Разбиваем на тренировочную и проверочную для dataY
  for col in columnsY:
    y_train[col] = dataY[col][mask_train]
    y_test[col] = dataY[col][mask_test]
 
  return x_train, x_test, y_train, y_test

# Делим датасет на обучающую и проверочную выборки
x_train, x_test, y_train, y_test = get_train_test_split(dataX_OHE, dataY_OHE_dict, mask_train, mask_test, columnsY)

print('Входные данные')
print(x_train.shape)
print(x_test.shape)
print()
for col_name in columnsY:
  print('Колонка ', col_name)
  print(y_train[col_name].shape)
  print(y_test[col_name].shape)
  print()

"""# Нейронка

## Архитектуры нейронок
"""

ns = {} # Словарь с нейронками

"""### AllCalls """

def createNN_AllCalls(n_in, n_out):
  '''
    Создаёт структуру НС для классификации
    n_in - размер входных данных
    n_out - кол-во классов
  '''
  model = Sequential()
  model.add(BatchNormalization(input_shape=(n_in,)))
  model.add(Dense(64, activation='relu'))
  model.add(Dropout(0.5))
  model.add(BatchNormalization())
  model.add(Dense(256, activation='relu'))
  model.add(Dropout(0.5))
  model.add(BatchNormalization())
  model.add(Dense(32, activation='relu'))
  model.add(Dense(n_out, activation='softmax'))

  return model


# Обучаем модель полученными данными
def fitNN_AllCalls(model, x_train, y_train, x_test, y_test,
                   epochs=1000, learning_rate=1e-6):
  '''
    Обучение НС
  '''
  model.compile(optimizer=Adam(learning_rate=learning_rate), 
                loss='categorical_crossentropy', metrics=['accuracy'])

  history = model.fit(x_train, 
                      y_train, 
                      epochs=epochs, 
                      batch_size=100,
                      validation_data=(x_test, y_test))

  # Выводим график точности на обучающей выборке
  # label - имя графика в легенде
  plt.plot(history.history['accuracy'], 
          label='Доля верных ответов на обучающем наборе')

  # Выводим график точности на проверочной выборке
  plt.plot(history.history['val_accuracy'], 
          label='Доля верных ответов на проверочном наборе')

  # Выводим подписи осей
  plt.xlabel('Эпоха обучения')
  plt.ylabel('Доля верных ответов')

  # Выводим легенду
  plt.legend()
  plt.show()

  # Выводим графики ошибки
  plt.plot(history.history['loss'], 
          label='Ошибка на обучающем наборе')
  plt.plot(history.history['val_loss'], 
          label='Ошибка на проверочном наборе')
  plt.xlabel('Эпоха обучения')
  plt.ylabel('Ошибка')
  plt.legend()
  plt.show()

"""### Calls_n"""

def createNN_Calls_n(n_in, n_out):
  '''
    Создаёт структуру НС
    n_in - размер входных данных
    n_out - кол-во классов
  '''
  model = Sequential()
  model.add(BatchNormalization(input_shape=(n_in,)))
  model.add(Dense(32, activation='relu'))
  model.add(Dropout(0.3))
  model.add(BatchNormalization())
  model.add(Dense(128, activation='relu'))
  model.add(Dropout(0.3))
  model.add(BatchNormalization())
  model.add(Dense(32, activation='relu'))
  model.add(Dense(n_out, activation='softmax'))

  return model


# Обучаем модель полученными данными
def fitNN_Calls_n(model, x_train, y_train, x_test, y_test,
                  epochs=1000, learning_rate=1e-6):
  '''
    Обучение НС
  '''
  model.compile(optimizer=Adam(learning_rate=learning_rate), 
                loss='categorical_crossentropy', metrics=['accuracy'])

  history = model.fit(x_train, 
                      y_train, 
                      epochs=epochs, 
                      batch_size=100,
                      validation_data=(x_test, y_test))

  # Выводим график точности на обучающей выборке
  # label - имя графика в легенде
  plt.plot(history.history['accuracy'], 
          label='Доля верных ответов на обучающем наборе')

  # Выводим график точности на проверочной выборке
  plt.plot(history.history['val_accuracy'], 
          label='Доля верных ответов на проверочном наборе')

  # Выводим подписи осей
  plt.xlabel('Эпоха обучения')
  plt.ylabel('Доля верных ответов')

  # Выводим легенду
  plt.legend()
  plt.show()

  # Выводим графики ошибки
  plt.plot(history.history['loss'], 
          label='Ошибка на обучающем наборе')
  plt.plot(history.history['val_loss'], 
          label='Ошибка на проверочном наборе')
  plt.xlabel('Эпоха обучения')
  plt.ylabel('Ошибка')
  plt.legend()
  plt.show()

"""## Обучение.

### Создать заново все модели
"""

# Создать заново всё модели
ns['AllCalls'] = createNN_AllCalls(len(x_train[0]), len(y_train['AllCalls'][0]))
ns['calls(0)'] = createNN_Calls_n(len(x_train[0]), len(y_train['AllCalls'][0]))
ns['calls(-2)'] = createNN_Calls_n(len(x_train[0]), len(y_train['AllCalls'][0]))
ns['calls(-4)'] = createNN_Calls_n(len(x_train[0]), len(y_train['AllCalls'][0]))
ns['calls(-7)'] = createNN_Calls_n(len(x_train[0]), len(y_train['AllCalls'][0]))

"""### AllCalls"""

# Обучение
ns_name = 'AllCalls'                                                            # Название НС
ns[ns_name] = createNN_AllCalls(len(x_train[0]), len(y_train['AllCalls'][0]))   # Создать заново НС
fitNN_AllCalls(ns[ns_name], x_train, y_train[ns_name], x_test, y_test[ns_name], # Обучить НС
               epochs=400, learning_rate=1e-4)

# Дообучение
ns_name = 'AllCalls'                                                            # Название НС
fitNN_AllCalls(ns[ns_name], x_train, y_train[ns_name], x_test, y_test[ns_name], # Обучить НС
               epochs=50, learning_rate=1e-5)

"""### Calls(0)"""

# Обучение
ns_name = 'calls(0)'                                                            # Название НС
ns[ns_name] = createNN_Calls_n(len(x_train[0]), len(y_train['calls(0)'][0]))    # Создать заново НС
fitNN_Calls_n(ns[ns_name], x_train, y_train[ns_name], x_test, y_test[ns_name],  # Обучить НС
              epochs=200, learning_rate=1e-4)

# Дообучение
ns_name = 'calls(0)'                                                            # Название НС
fitNN_Calls_n(ns[ns_name], x_train, y_train[ns_name], x_test, y_test[ns_name],  # Обучить НС
              epochs=50, learning_rate=1e-4)

# Дообучение
ns_name = 'calls(0)'                                                            # Название НС
fitNN_Calls_n(ns[ns_name], x_train, y_train[ns_name], x_test, y_test[ns_name],  # Обучить НС
              epochs=50, learning_rate=1e-5)

"""### Calls(-2)"""

# Обучение
ns_name = 'calls(-2)'                                                           # Название НС
ns[ns_name] = createNN_Calls_n(len(x_train[0]), len(y_train['calls(-2)'][0]))   # Создать заново НС
fitNN_Calls_n(ns[ns_name], x_train, y_train[ns_name], x_test, y_test[ns_name],  # Обучить НС
              epochs=200, learning_rate=5e-5)

# Дообучение
ns_name = 'calls(-2)'                                                           # Название НС
fitNN_Calls_n(ns[ns_name], x_train, y_train[ns_name], x_test, y_test[ns_name],  # Обучить НС
              epochs=50, learning_rate=5e-5)

# Дообучение
ns_name = 'calls(-2)'                                                           # Название НС
fitNN_Calls_n(ns[ns_name], x_train, y_train[ns_name], x_test, y_test[ns_name],  # Обучить НС
              epochs=50, learning_rate=3e-5)

"""### Calls(-4)"""

# Обучение
ns_name = 'calls(-4)'                                                           # Название НС
ns[ns_name] = createNN_Calls_n(len(x_train[0]), len(y_train['calls(-4)'][0]))   # Создать заново НС
fitNN_Calls_n(ns[ns_name], x_train, y_train[ns_name], x_test, y_test[ns_name],  # Обучить НС
              epochs=50, learning_rate=1e-4)

# Дообучение
ns_name = 'calls(-4)'                                                           # Название НС
fitNN_Calls_n(ns[ns_name], x_train, y_train[ns_name], x_test, y_test[ns_name],  # Обучить НС
              epochs=50, learning_rate=1e-4)

# Дообучение
ns_name = 'calls(-4)'                                                           # Название НС
fitNN_Calls_n(ns[ns_name], x_train, y_train[ns_name], x_test, y_test[ns_name],  # Обучить НС
              epochs=50, learning_rate=1e-5)

"""### Calls(-7)"""

# Обучение
ns_name = 'calls(-7)'                                                           # Название НС
ns[ns_name] = createNN_Calls_n(len(x_train[0]), len(y_train['calls(-7)'][0]))   # Создать заново НС
fitNN_Calls_n(ns[ns_name], x_train, y_train[ns_name], x_test, y_test[ns_name],  # Обучить НС
              epochs=200, learning_rate=1e-4)

# Дообучение
ns_name = 'calls(-7)'                                                           # Название НС
fitNN_Calls_n(ns[ns_name], x_train, y_train[ns_name], x_test, y_test[ns_name],  # Обучить НС
              epochs=50, learning_rate=1e-4)

# Дообучение
ns_name = 'calls(-7)'                                                           # Название НС
fitNN_Calls_n(ns[ns_name], x_train, y_train[ns_name], x_test, y_test[ns_name],  # Обучить НС
              epochs=50, learning_rate=1e-5)

"""## Сохраняем НС вместе с весами"""

# Список имён моделей
names_model = list(ns.keys())

# Сохраняем список имён моделей
save_dict(path_main + 'models_class/name_models.pkl', names_model)

# Сохраняем модели
for name_model in names_model:
    ns[name_model].save(path_main + 'models_class/' + name_model + '.h5')

"""## Загрузить НС вместе с весами"""

# Получить список имён моделей
names_model = load_dict(path_main + 'models_class/name_models.pkl')

# Загружаем модели
ns = {}
for name_model in names_model:
    ns[name_model] = load_model(path_main + 'models_class/' + name_model + '.h5')

"""## Проверка результата MAE

### Функции проверки
"""

def calc_MAE_error_model(ns_name, dataY_dict, class_mean_dict, df_data, mask_test, mask_train, x_test, x_train, select='test'):
  '''
    Подсчёт MAE и ошибки 
    select - 'test', 'train'
  '''
  model = ns[ns_name]

  if select == 'test':
    x = x_test
    # Формируем правильные ответы
    y_true = np.array(df_data.loc[mask_test, ns_name]).astype(float)
  elif select == 'train':
    x = x_train
    # Формируем правильные ответы
    y_true = np.array(df_data.loc[mask_train, ns_name]).astype(float)

  # результат в OHE
  predict_OHE = model.predict(x)                                                
  #print(predict_OHE[0])

  # преобразование OHE выходных данных к номеру класса
  predict_num_class = np.array([np.argmax(pred) for pred in predict_OHE])
  #print(predict_num_class[0])

  # преобразование номера класса в класс (строка)
  class_dict = {i: j for i, j in enumerate(dataY_dict[ns_name + '_class_dict'])}# Получаем словарь классов {0: '135-150', 1: '180-195', 2: '195-200'...}
  #print(class_dict)
  predict_class = [class_dict[num] for num in predict_num_class]                # Массив с названиями классов ['15-30', '15-30', '0-15', '30-45', '30-45'...]
  #print(predict_class)

  # Формируем из предикта классов предикт из средних значений класса
  predict_mean = [class_mean_dict[name_class] for name_class in predict_class]
  #print(predict_mean)

  err = abs(y_true - predict_mean)                                              # считаем абсолютную ошибку
  #print(err)

  mae = round(err.mean(), 2)                                                    # считаем MAE - среднюю абсолютную ошибку
  #print(mae)

  return predict_class, err, mae 


def get_tables_result(ns_name, dataY_dict, class_mean_dict, df_data, mask_test, mask_train, x_test, x_train, rangeCalls):
  '''
    Возвращает таблицы с результатами подсчёта MAE для выбранных НС
  '''
  # таблица для MAE
  df_mae = pd.DataFrame(data=ns_names, columns=['ns_name'])                     # Создаём колонку ns_name с именами НС
  df_mae['MAE_test'] = ''                                                       # Создаём пустую колонку MAE_test для значений MAE на проверочной выборке
  df_mae['MAE_train'] = ''                                                      # Создаём пустую колонку MAE_train для значений MAE на тренировочной выборке
  df_mae['rangeCalls'] = ''                                                     # Создаём пустую колонку rangeCalls для диапазонов классов в кол-ве звонков

  # Считаем длину результирующей таблицы по максимальной длине таблица данных
  num_row = max([len(x_test), len(x_train)])

  # таблица для err с кол-вом строк num_row
  df_err = pd.DataFrame(index=[i for i in range(num_row)])

  # Цикл по НС
  for ns_name in ns_names:
    # Цикл по типу выборки (проверочная, тренировочная)
    for select in ['test', 'train']:
      # Предикт, подсчёт MAE и ошибки
      predict_class, err, mae = calc_MAE_error_model(ns_name, dataY_dict, class_mean_dict, df_data, mask_test, mask_train, x_test, x_train, select)
      name_col = ns_name + '_' + select + '_'

      # дополнить нулями если нужно
      num_add_row = num_row - len(predict_class)
      predict_class = np.append(predict_class, np.full(num_add_row, fill_value='', dtype='str'))
      err = np.append(err, np.zeros(num_add_row))

      err = np.round(err, 1)
     
      # Формируем таблицу
      if select == 'test':
        y_tmp = df_data.loc[mask_test, ns_name].values.astype(float)
        df_err[name_col + 'true'] = np.round(np.append(y_tmp, np.zeros(num_add_row)), 0)
        df_mae.loc[df_mae.ns_name == ns_name, 'MAE_test'] = mae
      elif select == 'train':
        y_tmp = df_data.loc[mask_train, ns_name].values.astype(float)
        df_err[name_col + 'true'] = np.round(np.append(y_tmp, np.zeros(num_add_row)), 0)
        df_mae.loc[df_mae.ns_name == ns_name, 'MAE_train'] = mae

      df_err[name_col + 'pred'] = predict_class
      df_err[name_col + 'err'] = err

    df_mae.loc[df_mae.ns_name == ns_name, 'rangeCalls'] = rangeCalls[ns_name] 

  return df_mae, df_err

"""### Ошибка и MAE"""

# Получаем результат
ns_name = columnsY                                                             # Имена НС соответствуют названиям колонок
df_mae, df_err = get_tables_result(ns_name, dataY_dict, class_mean_dict, df_data, mask_test, mask_train, x_test, x_train, rangeCalls)

# Таблица ошибок по разным НС
'''
  AllCalls      - имя НС
  test, train   - проверочная или тренировочная выборки
  true          - табличное (правильное)  значение
  pred          - передсказанное значение
  err           - абсолютная ошибка
'''
df_err.head(25)

# Таблица MAE
'''
  MAE_test - на проверочной выборке
  MAE_train - на обучающей выборке
  rangeCalls - диапазон кол-ва звонков
'''
df_mae

"""### Вывести результат по одной НС"""

# Выберите имя НС через индекс массива (0-4)
num = 3
ns_names = columnsY

df_err[df_err.columns[df_err.columns.str.find(ns_names[num]) == 0]].head(30)

"""# ВЫВОД

MAE получился на равне с моделью регрессии. В данном случае это результат для  диапазонов 

rangeCalls = 

{'AllCalls': 15, 

'calls(0)': 8, 

'calls(-2)': 3,

'calls(-4)': 4,

'calls(-7)': 2}
"""